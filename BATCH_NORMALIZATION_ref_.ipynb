{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RdhZ5mXDRJY6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVZGX9vZJVYw"
      },
      "source": [
        "Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AFV1JjZdJVYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be003526-caa1-42f1-8444-a0435f2ab6da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W8IKWEjkJVYw"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "LAYERS = [ tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.LeakyReLU(),\n",
        "    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.LeakyReLU(),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")]\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential(LAYERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YHVxFkNJJVYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "630fa77f-cc08-4890-ff87-7f0645f48674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbVQZkWNUUBZ",
        "outputId": "98760b88-ebc3-41f3-8763-531ee02e41b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               235500    \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 300)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 100)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5rKJye3JVYw",
        "jupyter": {
          "source_hidden": true
        },
        "outputId": "d08cda93-211d-4bed-aadb-a64824f6a995",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 - 8s - loss: 1.2819 - accuracy: 0.6229 - val_loss: 0.8886 - val_accuracy: 0.7160 - 8s/epoch - 5ms/step\n",
            "Epoch 2/10\n",
            "1719/1719 - 5s - loss: 0.7955 - accuracy: 0.7362 - val_loss: 0.7130 - val_accuracy: 0.7656 - 5s/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "1719/1719 - 5s - loss: 0.6816 - accuracy: 0.7721 - val_loss: 0.6427 - val_accuracy: 0.7900 - 5s/epoch - 3ms/step\n",
            "Epoch 4/10\n",
            "1719/1719 - 5s - loss: 0.6217 - accuracy: 0.7944 - val_loss: 0.5900 - val_accuracy: 0.8066 - 5s/epoch - 3ms/step\n",
            "Epoch 5/10\n",
            "1719/1719 - 5s - loss: 0.5832 - accuracy: 0.8074 - val_loss: 0.5582 - val_accuracy: 0.8200 - 5s/epoch - 3ms/step\n",
            "Epoch 6/10\n",
            "1719/1719 - 5s - loss: 0.5553 - accuracy: 0.8157 - val_loss: 0.5350 - val_accuracy: 0.8238 - 5s/epoch - 3ms/step\n",
            "Epoch 7/10\n",
            "1719/1719 - 5s - loss: 0.5338 - accuracy: 0.8224 - val_loss: 0.5157 - val_accuracy: 0.8304 - 5s/epoch - 3ms/step\n",
            "Epoch 8/10\n",
            "1719/1719 - 5s - loss: 0.5172 - accuracy: 0.8272 - val_loss: 0.5079 - val_accuracy: 0.8282 - 5s/epoch - 3ms/step\n",
            "Epoch 9/10\n",
            "1719/1719 - 5s - loss: 0.5040 - accuracy: 0.8288 - val_loss: 0.4895 - val_accuracy: 0.8388 - 5s/epoch - 3ms/step\n",
            "Epoch 10/10\n",
            "1719/1719 - 6s - loss: 0.4924 - accuracy: 0.8321 - val_loss: 0.4817 - val_accuracy: 0.8396 - 6s/epoch - 3ms/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid), verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD99onTBJVY0"
      },
      "source": [
        "# Batch Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCPE7qdQWz-h"
      },
      "source": [
        "#### Internal Covariate Shift\n",
        "* We define Internal Covariate Shift as the change in the\n",
        "distribution of network activations due to the change in\n",
        "network parameters during training. \n",
        "\n",
        "* To improve the training, we seek to reduce the internal covariate shift. By\n",
        "fixing the distribution of the layer inputs x as the training\n",
        "progresses, we expect to improve the training speed. \n",
        "\n",
        "* It has been long known (LeCun et al., 1998b; Wiesler & Ney,\n",
        "2011) that the network training converges faster if its inputs are whitened â€“ i.e., linearly transformed to have zero\n",
        "means and unit variances, and decorrelated. \n",
        "\n",
        "* As each layer observes the inputs produced by the layers below, it would\n",
        "be advantageous to achieve the same whitening of the inputs of each layer. \n",
        "\n",
        "* By whitening the inputs to each layer, we would take a step towards achieving the fixed distributions of inputs that would remove the ill effects of the\n",
        "internal covariate shift.\n",
        "\n",
        "reference [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8Q4jVmkhGyb"
      },
      "source": [
        "## Input: \n",
        "### Values of x over a mini-batch: $B = \\{x_{1...m}\\}$\n",
        "### Learnable parameters: $\\gamma$ and $\\beta$\n",
        "\n",
        "\n",
        "## Output: \n",
        "### $\\{z^{(i)} = BN _{\\gamma, \\beta}(x^{(i)})\\}$\n",
        "\n",
        "## Algorithm:\n",
        "\n",
        "### 1. mini-batch mean: $\\mu_B = \\frac{1}{m_B} \\sum_{i=1}^{m_B} x^{(i)}$\n",
        "\n",
        "### 2. mini-batch variance: $\\sigma_B^2 = \\frac{1}{m_B} \\sum_{i=1}^{m_B} (x^{(i)} - \\mu_B)^2$\n",
        "\n",
        "### 3. normalize: $\\hat{x}^{(i)} = \\frac{x^{(i)} - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}$\n",
        "\n",
        "### 4. scale and shift: $ z^{(i)} = \\gamma \\otimes  \\hat{x}^{(i)} + \\beta \\equiv BN _{\\gamma, \\beta}(x^{(i)})\\ $ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5rVfznphGyc"
      },
      "source": [
        "---\n",
        "\n",
        "## BN Approach One"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_vaZQzOIVa8H"
      },
      "outputs": [],
      "source": [
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DSuksCFDJVY0"
      },
      "outputs": [],
      "source": [
        "LAYERS_BN = [\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(300, activation=\"relu\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "]\n",
        "\n",
        "model = tf.keras.models.Sequential(LAYERS_BN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l469kef_JVY0",
        "outputId": "e5d90a23-0626-4211-9d0b-c1a70a994351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 784)              3136      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 300)               235500    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 271,346\n",
            "Trainable params: 268,978\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hjoyt-inhGye",
        "outputId": "b051914a-4ae5-4114-d58c-38f2dded3d09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2368.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "784 * 4 , 300 * 4 , 100 * 4\n",
        "\n",
        "784 * 4 + 300 * 4 + 100 * 4\n",
        "\n",
        "(784 * 4 + 300 * 4 + 100 * 4)/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Jk9nIqiHhGye",
        "outputId": "a0066f64-89c5-4f97-8ef5-034b80348b95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3136"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "784 * 4 # mean, variance, gamma and Beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uxGbCK_QhGyf",
        "outputId": "1dcc056d-fbcc-42ea-9001-14d8c3986c02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1200"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "300 * 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_hs5X8W6hGyf",
        "outputId": "88a5833e-25e1-4393-cf71-c95afd7cb1d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "100 *4 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "86qyhobAhGyf",
        "outputId": "9f5249a4-7da3-4c38-bb31-c3a55a6f5f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4736"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "3136 + 1200 + 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aCdqTqMAhGyg",
        "outputId": "bd018a06-6beb-4256-972e-4a68f4c9c1dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2368.0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "4736 / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "paYCL_jchGyg",
        "outputId": "805bdf38-81bb-4795-9c34-75c58a80546a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "268978.0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "266610 + 2368.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "G_AsLq49hGyg",
        "outputId": "be5e8dc3-c237-4c9f-8dbc-819d2244f6e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "271346"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "266610 + 4736"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "570XDURdVrsF",
        "outputId": "cce4468f-e8b0-4266-a2f0-17db00f6be35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "variable name: gamma, \n",
            "is trainable: True\n",
            "\n",
            "\n",
            "variable name: beta, \n",
            "is trainable: True\n",
            "\n",
            "\n",
            "variable name: moving_mean, \n",
            "is trainable: False\n",
            "\n",
            "\n",
            "variable name: moving_variance, \n",
            "is trainable: False\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bn1 = model.layers[1]\n",
        "for variable in bn1.variables:\n",
        "    print(f\"variable name: {variable.name.split('/')[-1][:-2]}, \\nis trainable: {variable.trainable}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dht-K8XzJVY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff1e1be-c1ff-4d5b-d3e6-f6328a36b6ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTm-uyUdJVY0",
        "outputId": "3a99d764-3d0e-477f-fe19-ffa625f7a9e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 - 11s - loss: 0.8294 - accuracy: 0.7221 - val_loss: 0.5540 - val_accuracy: 0.8156 - 11s/epoch - 6ms/step\n",
            "Epoch 2/10\n",
            "1719/1719 - 9s - loss: 0.5703 - accuracy: 0.8035 - val_loss: 0.4792 - val_accuracy: 0.8380 - 9s/epoch - 5ms/step\n",
            "Epoch 3/10\n",
            "1719/1719 - 8s - loss: 0.5161 - accuracy: 0.8213 - val_loss: 0.4424 - val_accuracy: 0.8494 - 8s/epoch - 5ms/step\n",
            "Epoch 4/10\n",
            "1719/1719 - 9s - loss: 0.4789 - accuracy: 0.8314 - val_loss: 0.4213 - val_accuracy: 0.8558 - 9s/epoch - 5ms/step\n",
            "Epoch 5/10\n",
            "1719/1719 - 9s - loss: 0.4548 - accuracy: 0.8407 - val_loss: 0.4051 - val_accuracy: 0.8608 - 9s/epoch - 5ms/step\n",
            "Epoch 6/10\n",
            "1719/1719 - 9s - loss: 0.4387 - accuracy: 0.8444 - val_loss: 0.3930 - val_accuracy: 0.8638 - 9s/epoch - 5ms/step\n",
            "Epoch 7/10\n",
            "1719/1719 - 9s - loss: 0.4255 - accuracy: 0.8503 - val_loss: 0.3830 - val_accuracy: 0.8632 - 9s/epoch - 5ms/step\n",
            "Epoch 8/10\n",
            "1719/1719 - 9s - loss: 0.4123 - accuracy: 0.8539 - val_loss: 0.3758 - val_accuracy: 0.8666 - 9s/epoch - 5ms/step\n",
            "Epoch 9/10\n",
            "1719/1719 - 9s - loss: 0.4027 - accuracy: 0.8580 - val_loss: 0.3689 - val_accuracy: 0.8684 - 9s/epoch - 5ms/step\n",
            "Epoch 10/10\n",
            "1719/1719 - 9s - loss: 0.3925 - accuracy: 0.8613 - val_loss: 0.3630 - val_accuracy: 0.8670 - 9s/epoch - 5ms/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid), verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0icIdcZwhGyi"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRjNVhquJVY1"
      },
      "source": [
        "## BN Approach Two\n",
        "\n",
        "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a `BatchNormalization` layer does not need to have bias terms, since the `BatchNormalization` layer some as well, it would be a waste of parameters, so you can set `use_bias=False` when creating those layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5JCHlVSGY8Ik"
      },
      "outputs": [],
      "source": [
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fki0W4qwJVY1"
      },
      "outputs": [],
      "source": [
        "LAYERS_BN_BIAS_FALSE = [\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(300, use_bias=False),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation(\"relu\"),\n",
        "    tf.keras.layers.Dense(100, use_bias=False),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation(\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "]\n",
        "\n",
        "model = tf.keras.models.Sequential(LAYERS_BN_BIAS_FALSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tNbmgUjEJVY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d7ac0c-22e9-4ebb-a886-18c2c95d6548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkDJQ3QGJVY1",
        "outputId": "9a83fa9b-7e56-40f7-dbfe-0b48aaeb416d",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 12s 6ms/step - loss: 1.0346 - accuracy: 0.6739 - val_loss: 0.6680 - val_accuracy: 0.7884\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.6757 - accuracy: 0.7819 - val_loss: 0.5537 - val_accuracy: 0.8212\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.5961 - accuracy: 0.8021 - val_loss: 0.4996 - val_accuracy: 0.8352\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.5456 - accuracy: 0.8176 - val_loss: 0.4655 - val_accuracy: 0.8458\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.5140 - accuracy: 0.8250 - val_loss: 0.4419 - val_accuracy: 0.8510\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4915 - accuracy: 0.8309 - val_loss: 0.4237 - val_accuracy: 0.8540\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.4741 - accuracy: 0.8375 - val_loss: 0.4103 - val_accuracy: 0.8582\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4603 - accuracy: 0.8407 - val_loss: 0.3994 - val_accuracy: 0.8628\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.4465 - accuracy: 0.8458 - val_loss: 0.3911 - val_accuracy: 0.8640\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4338 - accuracy: 0.8500 - val_loss: 0.3828 - val_accuracy: 0.8682\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BATCH_NORMALIZATION_ref .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}